{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a43b937-beca-41cd-a649-16a977310174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6209a7-ef18-460e-a4bd-37c17aeb44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ENABLE_ONEDNN_OPTS=1\n",
    "home_dir = os.getenv(\"home_BA885\")\n",
    "\n",
    "# Assign home_dir as a local directory to use when saving data to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763df197-04cd-4696-a94b-db6e00b19ee3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Engineering\n",
    "\n",
    "The premise of machine learning is to use abundance of data and computational power to compensate for our lack of understanding and inadequate modeling. This, however, is not always guaranteed to succeed as it is quite common for a large and clean dataset to be absent or for out computational resources to be limited. In practice, a successful ML model lies somewhere on a spectrum that has Large Deep Neural Networks (large hypothesis space) on one end and Exact Mathematical Modeling with a handful of parameters on the other end, which requires making numerous assumptions about the data and its important features.\n",
    "\n",
    "The main distinction between the two ends of the spectrum is the size of the hypothesis space which has a direct correlation with the number of trainable parameters: the larger the number of parameters, the bigger the hypothesis space and the fewer the number of assumptions we need to make regarding the relevant features in our dataset.\n",
    "\n",
    "However, as we scale up the number of trainable parameters the model becomes more and more susceptible to overfitting and as the number of trainable parameters approaches the number of training samples this issue becomes harder and harder to mitigate. Furthermore, the larger the model the more resources are required to train and deploy it which may not be desirable, for instance when the deplyed model's response time needs to be minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977111d2-9d88-44c7-9527-d048d9c3c61b",
   "metadata": {},
   "source": [
    "## A simple binary classification problem\n",
    "\n",
    "The underlying principle in feature engineering is to gain a deeper understanding of the data. One approach is to train a simple deep neural network and observe its behavior.\n",
    "\n",
    "Here we will look at a toy example of MNIST restricted to identifying whether the input is an image of the digit 0 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5290748f-e3fa-41bf-a0b1-079a1285ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Rescale the data\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# Generate new labels that determine whether the digit is 0 or not\n",
    "# (label = 0 if the digit is 0 and label = 1 otherwise.)\n",
    "train_labels_0 = train_labels.astype('bool').astype('int')\n",
    "test_labels_0 = test_labels.astype('bool').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eea82855-ac36-4f58-b120-0169e748331d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_0_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 785       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a very simple model, we will do this through a function as we will be\n",
    "# initializing such a model multiple times.\n",
    "def ZeroOrNot(x = 'mnist_0_model'):\n",
    "    # Generates a model with input shape (28,28) and output shape (1)\n",
    "    mnist_0_input = layers.Input(shape=(28,28,))\n",
    "    mnist_0_flatten = layers.Flatten()(mnist_0_input)\n",
    "    mnist_0_output = layers.Dense(1, activation=\"sigmoid\")(mnist_0_flatten)\n",
    "    #\n",
    "    return keras.Model(inputs = mnist_0_input, outputs = mnist_0_output, name = x)\n",
    "\n",
    "mnist_0_model = ZeroOrNot('mnist_0_model')\n",
    "mnist_0_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a71464b6-4545-47b2-8ff4-3a367a893237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the optimizer, loss function and metrics with which to compile the model.\n",
    "# We will choose binary crossentropy as the loss function since the labels are 0 or 1\n",
    "# and the model output is a single number between 0 and 1.\n",
    "optim0 = \"rmsprop\"\n",
    "loss0 = \"binary_crossentropy\"\n",
    "metrics0 = [\"binary_accuracy\"]\n",
    "\n",
    "mnist_0_model.compile(optimizer = optim0, loss = loss0, metrics = metrics0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3dbdad3d-f400-48b1-8ba2-32349f10b8c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1797 - binary_accuracy: 0.9511 - val_loss: 0.0753 - val_binary_accuracy: 0.9808\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0571 - binary_accuracy: 0.9859 - val_loss: 0.0450 - val_binary_accuracy: 0.9872\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0409 - binary_accuracy: 0.9893 - val_loss: 0.0365 - val_binary_accuracy: 0.9900\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0355 - binary_accuracy: 0.9903 - val_loss: 0.0326 - val_binary_accuracy: 0.9910\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0328 - binary_accuracy: 0.9908 - val_loss: 0.0307 - val_binary_accuracy: 0.9918\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0311 - binary_accuracy: 0.9910 - val_loss: 0.0294 - val_binary_accuracy: 0.9913\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0299 - binary_accuracy: 0.9912 - val_loss: 0.0285 - val_binary_accuracy: 0.9909\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0290 - binary_accuracy: 0.9913 - val_loss: 0.0279 - val_binary_accuracy: 0.9918\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0282 - binary_accuracy: 0.9917 - val_loss: 0.0282 - val_binary_accuracy: 0.9919\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0278 - binary_accuracy: 0.9919 - val_loss: 0.0270 - val_binary_accuracy: 0.9919\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0272 - binary_accuracy: 0.9921 - val_loss: 0.0268 - val_binary_accuracy: 0.9918\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0269 - binary_accuracy: 0.9922 - val_loss: 0.0265 - val_binary_accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "# Set history = model.fit in order to store the loss and accuracy of the model after\n",
    "# each epoch. Utilize early stoppping callback.\n",
    "\n",
    "callb0 = keras.callbacks.EarlyStopping(monitor='val_binary_accuracy',\n",
    "                                       patience=3,\n",
    "                                       restore_best_weights=True\n",
    "                                      )\n",
    "\n",
    "history = mnist_0_model.fit(train_images, train_labels_0,\n",
    "                            validation_split = 0.2,\n",
    "                            epochs = 30,\n",
    "                            batch_size = 256,\n",
    "                            callbacks = callb0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "493895ea-27cb-4142-9ec2-21850a05549f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 883us/step - loss: 0.0232 - binary_accuracy: 0.9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.023230357095599174, 0.992900013923645]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset. Note that given the distribution of data\n",
    "# a model that always predicts \"not zero\" will have binary_accuracy ~ 0.90\n",
    "\n",
    "mnist_0_model.evaluate(test_images, test_labels_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25165da9-37a1-49be-b7ee-52d8e0cfdca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets look at what features the trained model is focusing on\n",
    "weights = mnist_0_model.layers[2].get_weights()[0]\n",
    "\n",
    "# Reshape to match the original image shape (28x28)\n",
    "weights = weights.reshape(28,28)\n",
    "\n",
    "# Plot the weights, the bright pixels correspond to the pixels the model\n",
    "# deems important features that help distinguish 0 from other digit images.\n",
    "plt.imshow(weights, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56a69b-bc85-470d-bce9-2518eac6a942",
   "metadata": {
    "tags": []
   },
   "source": [
    "It should not come as a surprise that the pixels the model focuses on resemble\n",
    "the digit 0. In fact if we look at what the average of all the images of the digit 0 looks like we will that it looks pretty similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e82eed9-445a-47c0-a31c-a77a6212ad2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take the average of all the images of the digit 0\n",
    "zero_indices = np.where(train_labels==0)\n",
    "average_zero_image = np.average(train_images[zero_indices],axis=0)\n",
    "\n",
    "plt.imshow(1 - average_zero_image, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ddd6cfd-2eee-4f2f-aac4-d184131b7847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01708952],\n",
       "       [1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can check easily check how much this average image overlaps with the\n",
    "# weights of the model\n",
    "mnist_0_model.predict(np.array([average_zero_image,\n",
    "                                1 - average_zero_image]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d6db0-279c-4615-b49c-7f835e631faa",
   "metadata": {},
   "source": [
    "## A toy model with only 3 trainable parameters\n",
    "\n",
    "The shallow (i.e. no hidden layers) model above, with 785 trainable parameters, can achieve ~99.2% accuracy using almost the entire training dataset.\n",
    "\n",
    "We now want to reduce the number of trainable parameter with some (ad-hoc) feature engineering and compare the results. I encourage you to try and build a model with a handful of parameters on you own. Below is an extreme example with only 3 trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1fcce43b-8096-4d32-8f34-6f5abce93414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_0_model_3p\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 28, 28)]     0           []                               \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)           (None, 784)          0           ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 1)            785         ['flatten_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 1)            785         ['flatten_10[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 2)            0           ['dense_24[0][0]',               \n",
      "                                                                  'dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 1)            3           ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,573\n",
      "Trainable params: 3\n",
      "Non-trainable params: 1,570\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compute the average of the images of 0 to use as a mask\n",
    "mask0 = np.average(train_images[zero_indices],axis=0).reshape((28*28,1))\n",
    "mask1 = 1 - mask0\n",
    "\n",
    "# Build a model with only 3 trainable parameters using our masks to identify 0s\n",
    "def ZeroOrNot_3p(x = 'mnist_0_model_3p'):\n",
    "    # Generates a model with input shape (28,28) and output shape (1)\n",
    "    # The model has 3 trainable parameters w0, w1 and b:\n",
    "    # Input x --> output = sigmoid( w0*mask0(x) + w1*mask1(x) + b )\n",
    "    mnist_0_input = layers.Input(shape=(28,28,))\n",
    "    mnist_0_flatten = layers.Flatten()(mnist_0_input)\n",
    "    mnist_0_mask_0 = layers.Dense(1)(mnist_0_flatten)\n",
    "    mnist_0_mask_1 = layers.Dense(1)(mnist_0_flatten)\n",
    "    mnist_0_concat = layers.Concatenate()([mnist_0_mask_0,mnist_0_mask_1])\n",
    "    mnist_0_output = layers.Dense(1, activation=\"sigmoid\")(mnist_0_concat)\n",
    "    #\n",
    "    mnist_0_model_3p = keras.Model(inputs = mnist_0_input, \n",
    "                                   outputs = mnist_0_output, \n",
    "                                   name = x)\n",
    "    #\n",
    "    # Set the weights of the mask layers\n",
    "    mnist_0_model_3p.layers[2].set_weights([mask0, np.zeros(1)])\n",
    "    mnist_0_model_3p.layers[3].set_weights([mask1, np.zeros(1)])\n",
    "    #\n",
    "    # Set the mask layers as not trainable\n",
    "    mnist_0_model_3p.layers[2].trainable = False\n",
    "    mnist_0_model_3p.layers[3].trainable = False\n",
    "    #\n",
    "    return mnist_0_model_3p\n",
    "\n",
    "mnist_0_model_3p = ZeroOrNot_3p()\n",
    "mnist_0_model_3p.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c380ed0d-da67-4f85-87bb-f06280841388",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 4.0387 - binary_accuracy: 0.9015 - val_loss: 2.8050 - val_binary_accuracy: 0.9000\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 2.1182 - binary_accuracy: 0.8368 - val_loss: 1.7574 - val_binary_accuracy: 0.8322\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.4508 - binary_accuracy: 0.8323 - val_loss: 1.1536 - val_binary_accuracy: 0.8559\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8808 - binary_accuracy: 0.8819 - val_loss: 0.6182 - val_binary_accuracy: 0.9003\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.4160 - binary_accuracy: 0.9017 - val_loss: 0.2524 - val_binary_accuracy: 0.9059\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1867 - binary_accuracy: 0.9425 - val_loss: 0.1471 - val_binary_accuracy: 0.9624\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1334 - binary_accuracy: 0.9629 - val_loss: 0.1250 - val_binary_accuracy: 0.9650\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1206 - binary_accuracy: 0.9650 - val_loss: 0.1193 - val_binary_accuracy: 0.9645\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1153 - binary_accuracy: 0.9663 - val_loss: 0.1141 - val_binary_accuracy: 0.9662\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1122 - binary_accuracy: 0.9663 - val_loss: 0.1132 - val_binary_accuracy: 0.9657\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1104 - binary_accuracy: 0.9671 - val_loss: 0.1105 - val_binary_accuracy: 0.9664\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1091 - binary_accuracy: 0.9667 - val_loss: 0.1096 - val_binary_accuracy: 0.9670\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1080 - binary_accuracy: 0.9670 - val_loss: 0.1084 - val_binary_accuracy: 0.9669\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.1071 - binary_accuracy: 0.9670 - val_loss: 0.1075 - val_binary_accuracy: 0.9668\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.1063 - binary_accuracy: 0.9669 - val_loss: 0.1072 - val_binary_accuracy: 0.9672\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.1055 - binary_accuracy: 0.9674 - val_loss: 0.1075 - val_binary_accuracy: 0.9654\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.1049 - binary_accuracy: 0.9674 - val_loss: 0.1061 - val_binary_accuracy: 0.9666\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.1042 - binary_accuracy: 0.9676 - val_loss: 0.1047 - val_binary_accuracy: 0.9676\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.1036 - binary_accuracy: 0.9673 - val_loss: 0.1047 - val_binary_accuracy: 0.9669\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.1029 - binary_accuracy: 0.9676 - val_loss: 0.1038 - val_binary_accuracy: 0.9679\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.1025 - binary_accuracy: 0.9675 - val_loss: 0.1029 - val_binary_accuracy: 0.9675\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.1020 - binary_accuracy: 0.9678 - val_loss: 0.1026 - val_binary_accuracy: 0.9678\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.1015 - binary_accuracy: 0.9677 - val_loss: 0.1024 - val_binary_accuracy: 0.9673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd3a686aa0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use the previously defined optimizer, loss function, metric and callback\n",
    "# (rmsprop, binary_crossentropy, binary_accuracy)\n",
    "\n",
    "mnist_0_model_3p.compile(optimizer = optim0, loss = loss0, metrics = metrics0)\n",
    "\n",
    "mnist_0_model_3p.fit(train_images, train_labels_0, validation_split = 0.2,\n",
    "                     epochs = 30, batch_size = 256, callbacks = callb0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e78b725b-8220-48b1-9c4c-87b0413fac11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0964 - binary_accuracy: 0.9683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09643455594778061, 0.9682999849319458]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the performance on the test dataset\n",
    "mnist_0_model_3p.evaluate(test_images, test_labels_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd8399-3595-4d71-a38a-3ce594659efb",
   "metadata": {},
   "source": [
    "The best this model can do is ~97.0% accuracy which is quite a poor performance even compared to the shallow model mnist_0_model which achieves ~99.2% accuracy on the test dataset.\n",
    "\n",
    "Would this still be the case if we had a smaller dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c75648df-78b5-4975-87ec-1bbb69cc3a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 12000 images the model accuracy = 0.9922000169754028\n",
      "with 6000 images the model accuracy = 0.9915000200271606\n",
      "with 600 images the model accuracy = 0.9821000099182129\n",
      "with 300 images the model accuracy = 0.9787999987602234\n"
     ]
    }
   ],
   "source": [
    "# Lets see how well our shallow model does with a smaller training dataset\n",
    "# We need to increase the patience of the early stopping callback\n",
    "callb1 = keras.callbacks.EarlyStopping(monitor='val_binary_accuracy',\n",
    "                                       patience=8,\n",
    "                                       restore_best_weights=True\n",
    "                                      )\n",
    "for n in [12000, 6000, 600, 300]:\n",
    "    model_785p = ZeroOrNot('mnist_0_model_785p_{}'.format(n))\n",
    "    model_785p.compile(optimizer = optim0, loss = loss0, metrics = metrics0)\n",
    "    #\n",
    "    model_785p.fit(train_images[:n], train_labels_0[:n],\n",
    "                   validation_data = (train_images[58000:], train_labels_0[58000:]),\n",
    "                   epochs = 100, batch_size = 128, callbacks = callb1, verbose = 0)\n",
    "    #\n",
    "    accuracy_785p = model_785p.evaluate(test_images, test_labels_0, verbose = 0)[1]\n",
    "    #\n",
    "    #\n",
    "    model_3p = ZeroOrNot_3p('mnist_0_model_3p_{}'.format(n))\n",
    "    model_3p.compile(optimizer = optim0, loss = loss0, metrics = metrics0)\n",
    "    #\n",
    "    model_3p.fit(train_images[:n], train_labels_0[:n],\n",
    "                 validation_data = (train_images[58000:], train_labels_0[58000:]),\n",
    "                 epochs = 200, batch_size = 128, callbacks = callb1, verbose = 0)\n",
    "    #\n",
    "model_785p.evaluate(test_images, test_labels_0, verbose = 0)[1]\n",
    "    print('with {} images the model accuracy = {}'.format(n, accuracy_785p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d4616919-abdc-4400-93c4-f70974ca6e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9606999754905701"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3p = ZeroOrNot_3p('mnist_0_model_3p_{}'.format(300))\n",
    "model_3p.compile(optimizer = optim0, loss = loss0, metrics = metrics0)\n",
    "#\n",
    "model_3p.fit(train_images[:300], train_labels_0[:300],\n",
    "             validation_data = (train_images[58000:], train_labels_0[58000:]),\n",
    "             epochs = 200, batch_size = 16, verbose = 0)\n",
    "#\n",
    "model_3p.evaluate(test_images, test_labels_0, callbacks = callb1, verbose = 0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cdb5db-621e-410e-aff9-832ee9e11afe",
   "metadata": {},
   "source": [
    "As we reduce the size of the training dataset our 785 parameter model starts to lose its edge over the 3 parameter model.\n",
    "\n",
    "Note: Run model_3p.fit multiple times so that it has chance to find a 'good' local minimum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
