{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unsupervised.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "u9glM401LbVG",
        "ygU64a1Vv5MZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised learning\n",
        "\n",
        "We will look at an example covered in \"Hands-on Unsupervised Learning Using Python\" by Ankur A. Patel. The accompanying material for the book can be found [here](https://github.com/aapatel09/handson-unsupervised-learning)."
      ],
      "metadata": {
        "id": "TooOfQIadhoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset from s3\n",
        "!pip install awscli\n",
        "!aws s3 cp s3://handson-unsupervised-learning/datasets/credit_card_data credit_card_data --recursive --no-sign-request"
      ],
      "metadata": {
        "id": "8PdbcRXJkOZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UTd2McdVdcVd"
      },
      "outputs": [],
      "source": [
        "import os, time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the data\n",
        "\n",
        "We will use a dataset containing credit card transactions from the book's accompanying material."
      ],
      "metadata": {
        "id": "XDit4NZIf5d2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('./credit_card_data/credit_card.csv')\n",
        "data.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "o2eq5J0OjkCE",
        "outputId": "16dad8b1-b499-4c8c-9d8e-63567ef70bc8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "\n",
              "[2 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e46e902-5ce4-48e8-b0f6-14bd72722e75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e46e902-5ce4-48e8-b0f6-14bd72722e75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e46e902-5ce4-48e8-b0f6-14bd72722e75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e46e902-5ce4-48e8-b0f6-14bd72722e75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the samples and labels.\n",
        "# We choose the class column as our labels which classifies transactions\n",
        "# as valid (0) or fraudulent (1).\n",
        "\n",
        "samples = data.copy().drop(['Class','Time'],axis=1)\n",
        "labels = data['Class'].copy()\n",
        "\n",
        "# Split the data into train and test sets\n",
        "\n",
        "train_samples, test_samples, train_labels, test_labels = train_test_split(\n",
        "    samples, labels, test_size = 0.33, random_state=2022, stratify = labels\n",
        ")\n",
        "\n",
        "# Print out the shape of the train and test data\n",
        "\n",
        "print('train samples: {}'.format(train_samples.shape))\n",
        "print('(valid, fraud) = ({},{})'.format(\n",
        "    (train_labels==0).sum(),(train_labels==1).sum()\n",
        "))\n",
        "\n",
        "print('test samples: {}'.format(test_samples.shape))\n",
        "print('(valid, fraud) = ({},{})'.format(\n",
        "    (test_labels==0).sum(),(test_labels==1).sum()\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi81oCORlAW-",
        "outputId": "3219dccc-3984-413b-f0b7-f43e54472e0f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples: (190820, 29)\n",
            "(valid, fraud) = (190490,330)\n",
            "test samples: (93987, 29)\n",
            "(valid, fraud) = (93825,162)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_means = samples.mean()\n",
        "t_stds = samples.std()"
      ],
      "metadata": {
        "id": "GSoPi3vL7OMV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "\n",
        "train_samples = (train_samples-t_means)/t_stds\n",
        "test_samples = (test_samples-t_means)/t_stds"
      ],
      "metadata": {
        "id": "qmzSdeg-tYql"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversample the fraudulent transactions\n",
        "\n",
        "osp = 64\n",
        "osr = 0.2\n",
        "\n",
        "train_os_samples = train_samples.copy()\n",
        "train_os_labels = train_labels.copy()\n",
        "\n",
        "train_os_samples = train_os_samples.append(\n",
        "    [train_os_samples[train_os_labels==1].sample(frac=0.2)]*osp,\n",
        "    ignore_index = False\n",
        ")\n",
        "\n",
        "train_os_labels = train_os_labels.append(\n",
        "    [train_os_labels[train_os_labels==1].sample(frac=0.2)]*osp,\n",
        "    ignore_index = False\n",
        ")"
      ],
      "metadata": {
        "id": "80v2CS_4ybN1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_os_samples.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH42GQTx0e-B",
        "outputId": "0e08d0b1-2ed1-4618-cfe0-bf9c679d2679"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(195044, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_os_samples, train_os_labels = shuffle(train_os_samples, train_os_labels)"
      ],
      "metadata": {
        "id": "t0GC58MX05HS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model"
      ],
      "metadata": {
        "id": "zQCEBMVOri5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = keras.Sequential([\n",
        "    layers.Input(shape=(29,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "metric = ['binary_accuracy',\n",
        "           keras.metrics.FalseNegatives(name='fn'),\n",
        "           keras.metrics.FalsePositives(name='fp'),]\n",
        "baseline_model.compile(optimizer='adam',\n",
        "                       loss='binary_crossentropy',\n",
        "                       metrics=metric)"
      ],
      "metadata": {
        "id": "4cenHCadm1Kw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model.fit(train_os_samples, train_os_labels,\n",
        "                   batch_size = 64, epochs=2,\n",
        "                   validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SyNlO3-snNy",
        "outputId": "edd3f1f8-4e59-4607-91ce-45ccf97cbaa2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "2439/2439 [==============================] - 19s 7ms/step - loss: 0.0313 - binary_accuracy: 0.9934 - fn: 522.0000 - fp: 512.0000 - val_loss: 0.0061 - val_binary_accuracy: 0.9982 - val_fn: 55.0000 - val_fp: 17.0000\n",
            "Epoch 2/2\n",
            "2439/2439 [==============================] - 17s 7ms/step - loss: 0.0076 - binary_accuracy: 0.9984 - fn: 146.0000 - fp: 105.0000 - val_loss: 0.0039 - val_binary_accuracy: 0.9990 - val_fn: 26.0000 - val_fp: 12.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9b88ab9690>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_eval = baseline_model.evaluate(test_samples, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6emuBj7osqD5",
        "outputId": "ac8e348d-5ccd-413a-afd3-732f63ccf90a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2938/2938 [==============================] - 14s 5ms/step - loss: 0.0049 - binary_accuracy: 0.9994 - fn: 30.0000 - fp: 31.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model.evaluate(test_samples[test_labels==1], test_labels[test_labels==1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEIk8uWPD7SF",
        "outputId": "7cd4c209-919a-48be-bfa6-24265581b25d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 5ms/step - loss: 1.9352 - binary_accuracy: 0.8148 - fn: 30.0000 - fp: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.935228705406189, 0.8148148059844971, 30.0, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_fn = int(baseline_eval[2])\n",
        "baseline_fp = int(baseline_eval[3])\n",
        "baseline_tn = (test_labels==0).sum()\n",
        "baseline_tp = (test_labels==1).sum()\n",
        "\n",
        "baseline_cm = np.array([[baseline_tp - baseline_fn, baseline_fn], \n",
        "                        [baseline_fp, baseline_tn - baseline_fp]])\n",
        "\n",
        "baseline_cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssVwKoI7EWeP",
        "outputId": "0c662510-d0e2-4350-f4c7-759df0ae0f9c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  132,    30],\n",
              "       [   31, 93794]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy of a constant model which classifies all transactions as valid\n",
        "\n",
        "1-162/93987"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4_XJvlJv6n8",
        "outputId": "0c46a88f-8560-4c3a-bf82-12b1bcaa90f3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9982763573685722"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsupervised model\n",
        "\n",
        "The key idea behind unsupervised learning for fraud/anomaly detection is to first train a generative model. Since the data is so unbalanced, the generative model will mostly learn to generate valid transactions. Fraudulent/anomalous transaction will thus be generated poorly marking them as fradulent."
      ],
      "metadata": {
        "id": "ER0pbU0jwf00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fd = keras.Sequential([\n",
        "    layers.Input(shape=(29,)),\n",
        "    layers.Dense(128, activity_regularizer=keras.regularizers.l1(10e-5)),\n",
        "    layers.LeakyReLU(alpha=0.2),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(32),\n",
        "    layers.LeakyReLU(alpha=0.2),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(128, activity_regularizer=keras.regularizers.l1(10e-5)),\n",
        "    layers.LeakyReLU(alpha=0.2),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(29)\n",
        "])\n",
        "\n",
        "model_fd.compile(optimizer='adam',\n",
        "                 loss='mse',\n",
        "                 metrics='accuracy')"
      ],
      "metadata": {
        "id": "0WGzaYqZwA7m"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fd.fit(train_os_samples, train_os_samples,\n",
        "             batch_size = 64, epochs = 3,\n",
        "             validation_split=0.2)"
      ],
      "metadata": {
        "id": "R7ej_L_O4BSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5174d8b0-83ef-403e-e839-fbe1b44379a0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2439/2439 [==============================] - 21s 9ms/step - loss: 0.2756 - accuracy: 0.5971 - val_loss: 0.0945 - val_accuracy: 0.8423\n",
            "Epoch 2/3\n",
            "2439/2439 [==============================] - 16s 6ms/step - loss: 0.2719 - accuracy: 0.6006 - val_loss: 0.0895 - val_accuracy: 0.8515\n",
            "Epoch 3/3\n",
            "2439/2439 [==============================] - 15s 6ms/step - loss: 0.2694 - accuracy: 0.5994 - val_loss: 0.0879 - val_accuracy: 0.8421\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9b86c4f390>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate reconstruction error\n",
        "\n",
        "def anomaly_scores(sample, reconstruction):\n",
        "    loss = np.sum((np.array(sample) - \n",
        "                   np.array(reconstruction))**2, axis=1)\n",
        "    loss = pd.Series(data=loss,index=sample.index)\n",
        "    loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "xkQCgBvv5ZaS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_scores = anomaly_scores(test_samples, model_fd.predict(test_samples))"
      ],
      "metadata": {
        "id": "ZcKhWOzK6Bg8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.02\n",
        "tn = (test_labels==0).sum()\n",
        "tp = (test_labels==1).sum()\n",
        "fn = (test_scores[test_labels==1]<=threshold).sum()\n",
        "fp = (test_scores[test_labels==0]>threshold).sum()\n",
        "cm = np.array([[tp - fn, fn], [fp, tn - fp]])\n",
        "\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBAY3sz48Wci",
        "outputId": "6b200683-ff08-4350-951f-6ed8cde5de64"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   27,   135],\n",
              "       [  331, 93494]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "\n",
        "(tp + tn - fp - fn)/(tp + tn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz_N7bc7939a",
        "outputId": "1b2617ab-83a9-4c79-c125-6c5aea20c8e9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9950418674923127"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using GANs"
      ],
      "metadata": {
        "id": "_a7_OM6vJW2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAN model class"
      ],
      "metadata": {
        "id": "u9glM401LbVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN model class\n",
        "\n",
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        # The model simultaneously optimizes the generator and the discriminator.\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_samples):\n",
        "        batch_size = tf.shape(real_samples)[0]\n",
        "        # Generate random latent vectors used by the generator.\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, self.latent_dim))\n",
        "        # Generator feedforward\n",
        "        generated_samples = self.generator(random_latent_vectors)\n",
        "        # Mix the real and fake samples.\n",
        "        combined_samples = tf.concat([generated_samples, \n",
        "                                      tf.cast(real_samples, tf.float32)], axis=0)\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))],\n",
        "            axis=0\n",
        "        )\n",
        "        # Introduce randomness which helps with training\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Discriminator feedforward\n",
        "            predictions = self.discriminator(combined_samples)\n",
        "            # Compute loss function with true labels.\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        # Update discriminator weights.\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, self.latent_dim))\n",
        "        \n",
        "        # Pretend that the data generated below is real.\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(\n",
        "                self.generator(random_latent_vectors))\n",
        "            # Compute loss function with misleading labels.\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        # Update generator weights.\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\"d_loss\": self.d_loss_metric.result(),\n",
        "                \"g_loss\": self.g_loss_metric.result()}"
      ],
      "metadata": {
        "id": "_uhznFyjLaF0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAN model"
      ],
      "metadata": {
        "id": "8ai_7kuZLiMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN discriminator\n",
        "\n",
        "discriminator = keras.Sequential(\n",
        "    [layers.Input(shape=(29,)),\n",
        "     layers.Dense(128, activity_regularizer=keras.regularizers.l1(10e-5)),\n",
        "     layers.LeakyReLU(alpha=0.2),\n",
        "     layers.Dropout(0.2),\n",
        "     layers.Dense(1, activation=\"sigmoid\"),],\n",
        "     name=\"discriminator\",)"
      ],
      "metadata": {
        "id": "9Y_pGAQ_L41T"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN generator\n",
        "\n",
        "latent_dim = 2\n",
        "\n",
        "generator = keras.Sequential(\n",
        "    [layers.Input(shape=(latent_dim,)),\n",
        "     layers.Dense(128, activity_regularizer=keras.regularizers.l1(10e-5)),\n",
        "     layers.LeakyReLU(alpha=0.2),\n",
        "     layers.Dropout(0.2),\n",
        "     layers.Dense(29),],\n",
        "     name='generator',)"
      ],
      "metadata": {
        "id": "cdsfQ36WBNXH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss_fn=keras.losses.MeanSquaredError(),\n",
        ")"
      ],
      "metadata": {
        "id": "vRl3bfVgNZ_y"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan.fit(train_samples, batch_size=64, epochs=10)"
      ],
      "metadata": {
        "id": "BpL8ARH4LpcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0669bb66-c3c5-44c5-d49f-4330e90db000"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2982/2982 [==============================] - 15s 5ms/step - d_loss: 0.1402 - g_loss: 0.4281\n",
            "Epoch 2/10\n",
            "2982/2982 [==============================] - 14s 5ms/step - d_loss: 0.1139 - g_loss: 0.5616\n",
            "Epoch 3/10\n",
            "2982/2982 [==============================] - 15s 5ms/step - d_loss: 0.1315 - g_loss: 0.5564\n",
            "Epoch 4/10\n",
            "2982/2982 [==============================] - 15s 5ms/step - d_loss: 0.1876 - g_loss: 0.5345\n",
            "Epoch 5/10\n",
            "2982/2982 [==============================] - 15s 5ms/step - d_loss: 0.1774 - g_loss: 0.5071\n",
            "Epoch 6/10\n",
            "2982/2982 [==============================] - 15s 5ms/step - d_loss: 0.1763 - g_loss: 0.5092\n",
            "Epoch 7/10\n",
            "2982/2982 [==============================] - 19s 6ms/step - d_loss: 0.2068 - g_loss: 0.5579\n",
            "Epoch 8/10\n",
            "2982/2982 [==============================] - 15s 5ms/step - d_loss: 0.1704 - g_loss: 0.5299\n",
            "Epoch 9/10\n",
            "2982/2982 [==============================] - 15s 5ms/step - d_loss: 0.1770 - g_loss: 0.5438\n",
            "Epoch 10/10\n",
            "2982/2982 [==============================] - 15s 5ms/step - d_loss: 0.1962 - g_loss: 0.5332\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9b86b50150>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = anomaly_scores(test_samples, generator(tf.random.normal(shape=(93987, latent_dim))))"
      ],
      "metadata": {
        "id": "j0xBsoQ2J0v8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOcFRVg4KnfT",
        "outputId": "495cd6bd-c2df-474b-be98-86d2ecd37955"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "275867    0.002453\n",
              "2463      0.003052\n",
              "189999    0.005345\n",
              "232988    0.001854\n",
              "99045     0.001297\n",
              "            ...   \n",
              "31158     0.002156\n",
              "190818    0.002343\n",
              "153041    0.001890\n",
              "103803    0.003314\n",
              "150824    0.001714\n",
              "Length: 93987, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.02\n",
        "tn = (test_labels==0).sum()\n",
        "tp = (test_labels==1).sum()\n",
        "fn = (scores[test_labels==1]<=threshold).sum()\n",
        "fp = (scores[test_labels==0]>threshold).sum()\n",
        "cm = np.array([[tp - fn, fn], [fp, tn - fp]])\n",
        "\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8vwddnQKv85",
        "outputId": "c3b85baf-1e61-41a0-ccd6-2e9544ce36f3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   70,    92],\n",
              "       [  572, 93253]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsupervised classification with VAEs"
      ],
      "metadata": {
        "id": "C-l3FbXMu2e8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VAE class"
      ],
      "metadata": {
        "id": "ygU64a1Vv5MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE subclassed model\n",
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.sampler = Sampler()\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.total_loss_tracker,\n",
        "                self.reconstruction_loss_tracker,\n",
        "                self.kl_loss_tracker]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of the encoder\n",
        "            z_mean, z_log_var = self.encoder(data)\n",
        "            # Forward pass of the sampler\n",
        "            z = self.sampler(z_mean, z_log_var)\n",
        "            # Forward pass of the decoder\n",
        "            reconstruction = decoder(z)\n",
        "            # Reconstruction loss compares the original image and its reconstructions\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction),\n",
        "                    axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            # KL loss pushes the distribution towards a normal dist. near the origin\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            total_loss = reconstruction_loss + tf.reduce_mean(kl_loss)\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        # Apply gradient descent\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        # Update the metrics\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"total_loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "chi9qy6Bv9b7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VAE model"
      ],
      "metadata": {
        "id": "k84gclQHwBQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 2\n",
        "\n",
        "# encoder\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
        "# Extract abstract features from the input\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "# Map the extracted features to the latent space\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "\n",
        "# Sampling layer which takes sample from the latent space using Gaussian\n",
        "# distribution with mean and variation z_mean and z_log_var.\n",
        "\n",
        "class Sampler(layers.Layer):\n",
        "    def call(self, z_mean, z_log_var):\n",
        "        batch_size = tf.shape(z_mean)[0]\n",
        "        z_size = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.random.normal(shape=(batch_size, z_size))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# decoder\n",
        "\n",
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((7, 7, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "decoder_outputs = layers.Conv2D(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var], name=\"encoder\")\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")"
      ],
      "metadata": {
        "id": "J-NnAP0au7Ab"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load all the images in the MNIST dataset ignoring the labels\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
        "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLq3gryNwSWv",
        "outputId": "20930dc5-3052-418d-d203-72148f6e5ae3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam(), run_eagerly=True)\n",
        "vae.fit(mnist_digits, epochs=30, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO2umTsuwbYm",
        "outputId": "31ea5d32-21cd-4fbd-f86c-ef617732eaad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "547/547 [==============================] - 36s 49ms/step - total_loss: 211.4789 - reconstruction_loss: 209.4141 - kl_loss: 2.0649\n",
            "Epoch 2/30\n",
            "547/547 [==============================] - 27s 50ms/step - total_loss: 186.1240 - reconstruction_loss: 183.8193 - kl_loss: 2.3047\n",
            "Epoch 3/30\n",
            "547/547 [==============================] - 27s 49ms/step - total_loss: 182.2005 - reconstruction_loss: 179.8562 - kl_loss: 2.3443\n",
            "Epoch 4/30\n",
            "547/547 [==============================] - 27s 49ms/step - total_loss: 178.2218 - reconstruction_loss: 175.6496 - kl_loss: 2.5722\n",
            "Epoch 5/30\n",
            "547/547 [==============================] - 27s 49ms/step - total_loss: 167.5904 - reconstruction_loss: 164.1121 - kl_loss: 3.4781\n",
            "Epoch 6/30\n",
            "547/547 [==============================] - 28s 51ms/step - total_loss: 158.4486 - reconstruction_loss: 154.5412 - kl_loss: 3.9075\n",
            "Epoch 7/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 155.5107 - reconstruction_loss: 151.5736 - kl_loss: 3.9371\n",
            "Epoch 8/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 153.9054 - reconstruction_loss: 149.9724 - kl_loss: 3.9329\n",
            "Epoch 9/30\n",
            "547/547 [==============================] - 27s 49ms/step - total_loss: 152.8645 - reconstruction_loss: 148.9251 - kl_loss: 3.9393\n",
            "Epoch 10/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 152.1009 - reconstruction_loss: 148.1768 - kl_loss: 3.9242\n",
            "Epoch 11/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 151.3236 - reconstruction_loss: 147.4219 - kl_loss: 3.9017\n",
            "Epoch 12/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 150.7619 - reconstruction_loss: 146.8691 - kl_loss: 3.8929\n",
            "Epoch 13/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 150.3608 - reconstruction_loss: 146.4769 - kl_loss: 3.8838\n",
            "Epoch 14/30\n",
            "547/547 [==============================] - 26s 47ms/step - total_loss: 149.9655 - reconstruction_loss: 146.0997 - kl_loss: 3.8658\n",
            "Epoch 15/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 149.6293 - reconstruction_loss: 145.7698 - kl_loss: 3.8594\n",
            "Epoch 16/30\n",
            "547/547 [==============================] - 27s 49ms/step - total_loss: 149.2732 - reconstruction_loss: 145.4140 - kl_loss: 3.8594\n",
            "Epoch 17/30\n",
            "547/547 [==============================] - 27s 49ms/step - total_loss: 148.9426 - reconstruction_loss: 145.0982 - kl_loss: 3.8446\n",
            "Epoch 18/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 148.7291 - reconstruction_loss: 144.8921 - kl_loss: 3.8370\n",
            "Epoch 19/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 148.4655 - reconstruction_loss: 144.6351 - kl_loss: 3.8304\n",
            "Epoch 20/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 148.1295 - reconstruction_loss: 144.3161 - kl_loss: 3.8133\n",
            "Epoch 21/30\n",
            "547/547 [==============================] - 27s 50ms/step - total_loss: 148.0375 - reconstruction_loss: 144.2138 - kl_loss: 3.8237\n",
            "Epoch 22/30\n",
            "547/547 [==============================] - 28s 51ms/step - total_loss: 147.7296 - reconstruction_loss: 143.9077 - kl_loss: 3.8218\n",
            "Epoch 23/30\n",
            "547/547 [==============================] - 28s 52ms/step - total_loss: 147.5737 - reconstruction_loss: 143.7628 - kl_loss: 3.8109\n",
            "Epoch 24/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 147.3409 - reconstruction_loss: 143.5330 - kl_loss: 3.8078\n",
            "Epoch 25/30\n",
            "547/547 [==============================] - 31s 57ms/step - total_loss: 147.1754 - reconstruction_loss: 143.3837 - kl_loss: 3.7915\n",
            "Epoch 26/30\n",
            "547/547 [==============================] - 30s 55ms/step - total_loss: 147.0754 - reconstruction_loss: 143.2827 - kl_loss: 3.7926\n",
            "Epoch 27/30\n",
            "547/547 [==============================] - 27s 49ms/step - total_loss: 146.9662 - reconstruction_loss: 143.1825 - kl_loss: 3.7836\n",
            "Epoch 28/30\n",
            "547/547 [==============================] - 27s 48ms/step - total_loss: 146.6991 - reconstruction_loss: 142.9145 - kl_loss: 3.7846\n",
            "Epoch 29/30\n",
            "547/547 [==============================] - 27s 49ms/step - total_loss: 146.5818 - reconstruction_loss: 142.8024 - kl_loss: 3.7796\n",
            "Epoch 30/30\n",
            "547/547 [==============================] - 27s 49ms/step - total_loss: 146.4817 - reconstruction_loss: 142.7042 - kl_loss: 3.7775\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9c00535350>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_distribution = encoder.predict(mnist_digits)"
      ],
      "metadata": {
        "id": "wVPFzIjVxtgG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = latent_distribution[0][:100,0]\n",
        "ys = latent_distribution[0][:100,1]\n",
        "\n",
        "plt.plot(xs,ys, \"ob\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "snXjlZ3myPUw",
        "outputId": "88e3f2c3-da47-4eb9-8efe-8c16ef1aa6c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xeYvdIJiyTtE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}