{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforced.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reinforcement Learning\n",
        "\n",
        "We will look at CartPole-V0 which is already implemented as part of [gym](https://gym.openai.com/envs/#classic_control) and is a simple game of balancing a pole on a plate by moving the plate along a single axis. \n",
        "\n",
        "Our agent or NN has two components:\n",
        "- Actor: Predicts the probability associated with each action (left or right) based on the state of the pole\n",
        "- Critic: Estimates the rewards the agent will receive in the future.\n",
        "\n",
        "We will use the rewards as the objective function to be maximized during training.\n",
        "\n",
        "\n",
        "Based on this [example](https://keras.io/examples/rl/actor_critic_cartpole/) by A. Nandan."
      ],
      "metadata": {
        "id": "p_uLQMdBXb35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "OM1TEPKBYby9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BAa6V7TLXJtr"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Configuration parameters for the whole setup\n",
        "seed = 42\n",
        "# Discount factor for past rewards\n",
        "gamma = 0.99\n",
        "# Number of steps before ending the session\n",
        "max_steps_per_episode = 10000\n",
        "\n",
        "# Create the environment\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "env.seed(seed)\n",
        "# Smallest number such that 1.0 + eps != 1.0\n",
        "eps = np.finfo(np.float32).eps.item()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_inputs = 4\n",
        "num_actions = 2\n",
        "num_hidden = 128\n",
        "\n",
        "inputs = layers.Input(shape=(num_inputs,))\n",
        "x = layers.Dense(128, activation=\"relu\")(inputs)\n",
        "action = layers.Dense(num_actions, activation=\"softmax\")(x)\n",
        "critic = layers.Dense(1)(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=[action, critic])"
      ],
      "metadata": {
        "id": "GSWgOUrvZCkX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, to_file='ActionCritic.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "K-31PpmdgVGm",
        "outputId": "8edc0d5c-b60d-4b16-9769-a822be62d4c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "vMXhkRUTZ7uM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the environment\n",
        "state = env.reset()"
      ],
      "metadata": {
        "id": "Z3kElJmSqwcu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feedforward\n",
        "model(tf.convert_to_tensor([state]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-9CQ0Fuqx45",
        "outputId": "376ff07b-003f-477d-cd4d-6fcb419dc586"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.5000212 , 0.49997875]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.01055172]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.step(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScK9RjDirqoM",
        "outputId": "a0ddad8e-e2a9-47ab-8e10-a697772326dc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.01820141, -0.17833326,  0.02500666,  0.32754535]), 1.0, False, {})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "# The loss function to use for the critic.\n",
        "huber_loss = keras.losses.Huber()\n",
        "# History of the feedforward passes.\n",
        "action_probs_history = []\n",
        "critic_value_history = []\n",
        "# History of the rewards\n",
        "rewards_history = []\n",
        "running_reward = 0\n",
        "episode_count = 0\n",
        "\n",
        "# Run episodes until solved.\n",
        "while True:\n",
        "    # Reset the environment after each run.\n",
        "    state = env.reset()\n",
        "    episode_reward = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Runs a maximum of max_steps unless the game end prematurely.\n",
        "        for timestep in range(1, max_steps_per_episode):\n",
        "            # Convert the state to a tf tensor.\n",
        "            state = tf.convert_to_tensor(state)\n",
        "            # Add an extra dim: shape=(x) --> (1,x)\n",
        "            state = tf.expand_dims(state, 0)\n",
        "\n",
        "            # Feedforward: predicts probabilities for the next action as well as\n",
        "            # the expected rewards.\n",
        "            action_probs, critic_value = model(state)\n",
        "            critic_value_history.append(critic_value[0, 0])\n",
        "\n",
        "            # Sample action from action probability distribution:\n",
        "            # action = 0 or 1 corresponds to the choice made, the log of the\n",
        "            # associated probability is then added to action_probs_history.\n",
        "            action = np.random.choice(num_actions, p=np.squeeze(action_probs))\n",
        "            action_probs_history.append(tf.math.log(action_probs[0, action]))\n",
        "\n",
        "            # Apply the sampled action in our environment\n",
        "            state, reward, done, _ = env.step(action)\n",
        "            rewards_history.append(reward)\n",
        "            episode_reward += reward\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # Update running reward to check condition for solving\n",
        "        running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
        "\n",
        "        # Calculate expected value from rewards\n",
        "        # - At each timestep what was the total reward received after that timestep\n",
        "        # - Rewards in the past are discounted by multiplying them with gamma\n",
        "        # - These are the labels for our critic\n",
        "        returns = []\n",
        "        discounted_sum = 0\n",
        "        for r in rewards_history[::-1]:\n",
        "            discounted_sum = r + gamma * discounted_sum\n",
        "            returns.insert(0, discounted_sum)\n",
        "\n",
        "        # Normalize\n",
        "        returns = np.array(returns)\n",
        "        returns = (returns - np.mean(returns)) / (np.std(returns) + eps)\n",
        "        returns = returns.tolist()\n",
        "\n",
        "        # Calculating loss values to update our network\n",
        "        history = zip(action_probs_history, critic_value_history, returns)\n",
        "        actor_losses = []\n",
        "        critic_losses = []\n",
        "        for log_prob, value, ret in history:\n",
        "            # At this point in history, the critic estimated that we would get a\n",
        "            # total reward = `value` in the future. We took an action with log probability\n",
        "            # of `log_prob` and ended up recieving a total reward = `ret`.\n",
        "            # The actor must be updated so that it predicts an action that leads to\n",
        "            # high rewards (compared to critic's estimate) with high probability.\n",
        "            diff = ret - value\n",
        "            # Actor loss:\n",
        "            actor_losses.append(-log_prob * diff)\n",
        "\n",
        "            # Critic loss:\n",
        "            # The critic must be updated so that it predicts a better estimate of\n",
        "            # the future rewards.\n",
        "            critic_losses.append(\n",
        "                huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0))\n",
        "            )\n",
        "\n",
        "        # Backpropagation\n",
        "        loss_value = sum(actor_losses) + sum(critic_losses)\n",
        "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        # Clear the loss and reward history\n",
        "        action_probs_history.clear()\n",
        "        critic_value_history.clear()\n",
        "        rewards_history.clear()\n",
        "\n",
        "    # Log details\n",
        "    episode_count += 1\n",
        "    if episode_count % 10 == 0:\n",
        "        template = \"running reward: {:.2f} at episode {}\"\n",
        "        print(template.format(running_reward, episode_count))\n",
        "\n",
        "    if running_reward > 195:  # Condition to consider the task solved\n",
        "        print(\"Solved at episode {}!\".format(episode_count))\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN5f6_2bZ6VG",
        "outputId": "0642ef03-6aa3-4f72-8e21-1a113476c229"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running reward: 7.00 at episode 10\n",
            "running reward: 10.95 at episode 20\n",
            "running reward: 16.84 at episode 30\n",
            "running reward: 19.53 at episode 40\n",
            "running reward: 16.09 at episode 50\n",
            "running reward: 14.41 at episode 60\n",
            "running reward: 13.68 at episode 70\n",
            "running reward: 13.86 at episode 80\n",
            "running reward: 14.10 at episode 90\n",
            "running reward: 16.07 at episode 100\n",
            "running reward: 15.85 at episode 110\n",
            "running reward: 15.74 at episode 120\n",
            "running reward: 15.23 at episode 130\n",
            "running reward: 16.86 at episode 140\n",
            "running reward: 34.96 at episode 150\n",
            "running reward: 25.52 at episode 160\n",
            "running reward: 19.48 at episode 170\n",
            "running reward: 15.66 at episode 180\n",
            "running reward: 13.49 at episode 190\n",
            "running reward: 11.98 at episode 200\n",
            "running reward: 11.06 at episode 210\n",
            "running reward: 10.33 at episode 220\n",
            "running reward: 10.22 at episode 230\n",
            "running reward: 10.06 at episode 240\n",
            "running reward: 9.91 at episode 250\n",
            "running reward: 9.80 at episode 260\n",
            "running reward: 9.74 at episode 270\n",
            "running reward: 9.95 at episode 280\n",
            "running reward: 9.71 at episode 290\n",
            "running reward: 9.86 at episode 300\n",
            "running reward: 9.82 at episode 310\n",
            "running reward: 10.13 at episode 320\n",
            "running reward: 10.26 at episode 330\n",
            "running reward: 10.77 at episode 340\n",
            "running reward: 12.90 at episode 350\n",
            "running reward: 13.86 at episode 360\n",
            "running reward: 14.71 at episode 370\n",
            "running reward: 32.81 at episode 380\n",
            "running reward: 47.67 at episode 390\n",
            "running reward: 68.28 at episode 400\n",
            "running reward: 50.15 at episode 410\n",
            "running reward: 35.60 at episode 420\n",
            "running reward: 25.77 at episode 430\n",
            "running reward: 20.15 at episode 440\n",
            "running reward: 17.56 at episode 450\n",
            "running reward: 33.26 at episode 460\n",
            "running reward: 44.56 at episode 470\n",
            "running reward: 61.19 at episode 480\n",
            "running reward: 80.97 at episode 490\n",
            "running reward: 101.96 at episode 500\n",
            "running reward: 107.22 at episode 510\n",
            "running reward: 100.58 at episode 520\n",
            "running reward: 93.33 at episode 530\n",
            "running reward: 117.81 at episode 540\n",
            "running reward: 142.17 at episode 550\n",
            "running reward: 165.38 at episode 560\n",
            "running reward: 178.33 at episode 570\n",
            "running reward: 133.21 at episode 580\n",
            "running reward: 93.07 at episode 590\n",
            "running reward: 65.80 at episode 600\n",
            "running reward: 51.62 at episode 610\n",
            "running reward: 46.13 at episode 620\n",
            "running reward: 43.36 at episode 630\n",
            "running reward: 38.31 at episode 640\n",
            "running reward: 40.33 at episode 650\n",
            "running reward: 38.47 at episode 660\n",
            "running reward: 41.65 at episode 670\n",
            "running reward: 48.28 at episode 680\n",
            "running reward: 47.64 at episode 690\n",
            "running reward: 52.53 at episode 700\n",
            "running reward: 59.80 at episode 710\n",
            "running reward: 70.13 at episode 720\n",
            "running reward: 72.67 at episode 730\n",
            "running reward: 79.27 at episode 740\n",
            "running reward: 83.79 at episode 750\n",
            "running reward: 91.49 at episode 760\n",
            "running reward: 95.59 at episode 770\n",
            "running reward: 106.70 at episode 780\n",
            "running reward: 114.31 at episode 790\n",
            "running reward: 119.59 at episode 800\n",
            "running reward: 137.38 at episode 810\n",
            "running reward: 162.51 at episode 820\n",
            "running reward: 177.55 at episode 830\n",
            "running reward: 186.56 at episode 840\n",
            "running reward: 179.92 at episode 850\n",
            "running reward: 181.88 at episode 860\n",
            "running reward: 179.23 at episode 870\n",
            "running reward: 164.44 at episode 880\n",
            "running reward: 149.76 at episode 890\n",
            "running reward: 131.89 at episode 900\n",
            "running reward: 133.67 at episode 910\n",
            "running reward: 153.09 at episode 920\n",
            "running reward: 171.91 at episode 930\n",
            "running reward: 174.17 at episode 940\n",
            "running reward: 180.56 at episode 950\n",
            "running reward: 173.50 at episode 960\n",
            "running reward: 168.84 at episode 970\n",
            "running reward: 174.75 at episode 980\n",
            "running reward: 176.75 at episode 990\n",
            "running reward: 183.13 at episode 1000\n",
            "running reward: 189.90 at episode 1010\n",
            "running reward: 193.95 at episode 1020\n",
            "Solved at episode 1024!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brSaNZeiIR7h"
      },
      "source": [
        "## Visualization\n",
        "In early stages of training:\n",
        "\n",
        "![Imgur](https://i.imgur.com/5gCs5kH.gif)\n",
        "\n",
        "In later stages of training:\n",
        "\n",
        "![Imgur](https://i.imgur.com/5ziiZUD.gif)\n"
      ]
    }
  ]
}